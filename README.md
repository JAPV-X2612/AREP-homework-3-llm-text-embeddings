# AREP-homework-3-llm-text-embeddings
LLM Text Preprocessing Foundations: Implementation of tokenization,  embedding layers, and data sampling techniques for training Large  Language Models (LLMs). Based on Sebastian Raschka's "Build a Large Language  Model (From Scratch)" - Chapter 2. Includes experiments on context  window overlap and embedding dimensionality.
